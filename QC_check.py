# Python script for checking velocity and discharge convergence from the _PO.csv generated by TUFLOW# Step 1 - enter terrain NAME as name parameter# Step 2 - enter run number as 'run_num' parameter# Step 3 - If the folder in F:/tuflow_runs is a re-run with a timestamp,#           enter the timestamp as 'tmstmp' parameter and toggle the commenting to include that declaration# Step 4 - indicate PO type: V for points or Q for lines# Step 5 - review the plots and the new _PO__convergence_times.csv generated and saved in discharge folderimport osimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltfrom shutil import rmtreeos.chdir('C:/Users/danie/Desktop/WETlab/tuflow-wf_python3')FOLDER = 'sfe_24_tuflow_20200923-153923'def convergence(FOLDER):    check_length = 20 # number of values to check back for convergence    tolerance_V = 0.005# error tolerance (fractional difference) for velocity    tolerance_Q = 0.005    # error tolerance (fractional difference) for discharge    slope_thr_V = 100    # slope threshold for linear regression line [velocity/time]    slope_thr_Q = 100    # slope threshold for linear regression line [discharge/time]    potypes = ['Q','V']    # get header PO names    #split folder name into terrain name and timestamp if applicable    tsbreak = FOLDER.find('_tuflow')    name = FOLDER[:tsbreak]    tmstmp = FOLDER[tsbreak +7:]    results_folder = os.path.abspath("C:/Users/danie/Desktop/WETlab/tuflow-wf_python3/tuflow_runs/" + FOLDER + "/results/")    allfiles = os.listdir(results_folder)    runs = []    for i in range(len(allfiles)):        if allfiles[i].startswith('0'):            runs.append(allfiles[i])    for potype in potypes    file = name + '_2d_' +  potype + '.csv'        directory = ("C:/Users/danie/Desktop/WETlab/tuflow-wf_python3/tuflow_runs/" + name + "_tuflow" + tmstmp + "/results/" + run_num + "/plot/csv/")        path = directory + file        with open(path) as f:            lines = f.readlines()            header = lines[0]            header = header.replace("\"", "").replace("\n", "").split(',')[1:]        #rename Time column        header[0] = 'Time'        # parse PO csv to dataframe        df = pd.read_csv(path, header=None, skiprows=3)        df = df.drop(0, axis=1)        df.columns = header        pos = header[1:]        #iterate over PO and plot/save to .png        for po in pos:            plt.clf()            x = df.Time            plt.xlabel('Time (hrs)', fontsize=12)            y = df[po]            plt.plot(x, y)            plt.title(' Run ' + run_num + 'at ' + po)            if potype == 'V':                plt.ylabel('Velocity (ft/s)', fontsize=12)            else:                plt.ylabel('Discharge (cfs)', fontsize=12)         #   new_path = os.path.join(directory, path)            plt.savefig(directory + name + '_' + run_num + '_' + po + '.png')        # check that PO name convention begins with 'Pt' or 'Ln'        for po in pos:            if not (po.startswith('Q') or po.startswith('V')):                raise SyntaxError("Name convention not satisfied for: %s.\nVelocity point observation names should begin with \'V\'\nDischarge line observations should begin with \'Q\'" % po)        # initialize convergence times dict ('DNC' = does not converge)        convergence_time = {po: ['DNC'] for po in pos}        # iterate over po locations        for po in pos:            print('checking %s...' % po)            if po.startswith('V'):                slope_thr = slope_thr_V                tolerance = tolerance_V            if po.startswith('Q'):                slope_thr = slope_thr_Q                tolerance = tolerance_Q            # iterate down column            for i in range(check_length, len(df.Time)):                # collect last 20 values and check slope of linear regression line                t = df.Time[i - check_length: i]                vals = df[po][i - check_length: i]                slope, yint = np.polyfit(t, vals, deg=1)                # calculate fractional differences between value at i previous values                frac_diffs = []                # if current check value is not 0                if df[po][i]:                    # iterate over previous check_length values                    for di in range(check_length):                        # if previous value in also not 0                        if df[po][i - check_length + di]:                            # calculate fractional difference between previous values and check value                            frac_diff = abs((df[po][i] - df[po][i - check_length + di]) / df[po][i])                            frac_diffs.append(frac_diff)                        # skip to next timestep if any df[po][i - check_length + di] == 0                        else:                            frac_diffs.append(np.nan)                            break                # skip to next timestep if df[po][i] == 0                else:                    frac_diffs.append(np.nan)                if not np.nan in frac_diffs:                    # check if previous check_val (e.g. 20) values are all within tolerance                    if np.all(np.asarray(frac_diffs) <= tolerance):                        # check if slope of linear regression is within slope threshold                        if abs(slope) <= slope_thr:                            convergence_time[po] = [df.Time[i]]                            break    # make separate dataframes for monitoring points (for velocity) and lines (for discharge)    pts = {i: v for i, v in convergence_time.items() if i.startswith('V')}    pts_df = pd.DataFrame.from_dict(pts)    lns = {i: v for i, v in convergence_time.items() if i.startswith('Q')}    lns_df = pd.DataFrame.from_dict(lns)    # save dataframe of convergence time for all observation points/lines    conv_df = pd.DataFrame.from_dict(convergence_time)    conv_path = path.replace('.csv', '_convergence_times.csv')    conv_df.to_csv(conv_path, index=False)    print('\nsaved convergence time table: %s\n' % conv_path)    # print summary to console    print(pts_df)    print(lns_df)    # flatten array function (used to calculate max convergence times below)    flatten = lambda l: [val[0] for val in l]    if potype == 'V':        try:            print('\nvelocity convergence at t = %.2f' % max(flatten(pts.values())))        except TypeError:            print('\nvelocities DO NOT CONVERGE!')    else:        try:            print('discharge convergence at t = %.4f' % max(flatten(lns.values())))        except TypeError:            print('discharges DO NOT CONVERGE!')    print('\nvelocity convergence = previous %i values have less than %.4f%% deviation and met the slope threshold value of %.4f' % (check_length, tolerance_V * 100, slope_thr_V))    print('\ndischarge convergence = previous %i values have less than %.4f%% deviation and met the slope threshold value of %.4f' % (check_length, tolerance_Q * 100, slope_thr_Q))    # create text file recording the error tolerance and slope thresholds set    text_path = path.replace('.csv', '_convergence_criteria.txt')    f = open(text_path, 'w+')    f.write('\ncheck length = previous %i values were checked' % (check_length))    f.write('\nerror tolerance for velocity = %.4f%%' % (tolerance_V * 100))    f.write('\nslope threshold for velocity = %.4f' % (slope_thr_V))    f.write('\nerror tolerance for discharge = %.4f%%' % (tolerance_Q * 100))    f.write('\nslope threshold for discharge = %.4f' % (slope_thr_Q))    f.close()def delete_grids:    NAME = 'sfe_24'    tmstmp = '_20200923-153923'    results_folder = os.path.abspath("F:/tuflow_runs/" + NAME + "_tuflow" + tmstmp + "/results/")    allfiles = os.listdir(results_folder)    extra_folders = []    for i in allfiles:        if i[0] != '0':            print('found ' + i)            extra_folders.append(i)    for i in extra_folders:        allfiles.remove(i)        print ('deleting ' + i)    for i in allfiles:        path = os.path.abspath(results_folder + '\\' + i + '\\grids')        if os.path.exists(path):            rmtree(path)